{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Authored by: Christina Curlette and Alexey Radul, Ph.D. of the MIT Probabilistic Computing Project (Probcomp). Prepared for: The DARPA PPAML PI meeting, July 2017.\n",
    "## 0. Jupyter notebooks\n",
    "If you've never worked with Jupyter (formerly iPython) notebooks before, you may want to briefly check out [the Jupyter website](http://jupyter.org/) to get familiar with the format. Jupyter notebooks allow you to intersperse cells of code, text, images, etc. in the same file. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# This is a code cell. You can run it by hitting the button in the toolbar that looks like a \"play\" button. \n",
    "# You can also hit Shift + Enter to run the cell.\n",
    "\n",
    "print 'hello world'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BayesDB\n",
    "The BayesDB project aims to enable BayesDB users to query the probable implications of their data as easily as querying the data itself. Why is this important? Stakeholders in business, humanitarian work, science, and government are increasingly recognizing the importance of making statistical inferences from their data. Existing approaches to this problem require experts in statistical modeling or data scientists proficient in applied machine learning. These skills are projected to be in short supply as the importance of statistical inference is increasingly recognized across a variety of fields. Also, developers new to machine learning may be stymied by the maze that is the current machine learning toolkit. This toolkit can come up short in settings that don’t match canonical machine learning problems.\n",
    "\n",
    "BayesDB aims to address some of these issues with three core capabilities:\n",
    "First, the Bayesian query language, or BQL, supports flexible data analysis queries while abstracting away the choice of model. Second, this BQL abstraction is enabled by general purpose default models that are capable of handling arbitrary tabular data. Finally, BayesDB is extensible by supporting integration of external statistical models and domain knowledge, when it’s available.\n",
    "\n",
    "The default probabilistic model used in BayesDB is CrossCat, described below.\n",
    "\n",
    "## 2. CrossCat\n",
    "CrossCat is a domain-general, Bayesian method for analyzing high-dimensional data tables. CrossCat estimates the full joint distribution over the variables in the table from the data, via approximate inference in a hierarchical, nonparametric Bayesian model, and provides efficient samplers for every conditional distribution. CrossCat combines strengths of nonparametric mixture modeling and Bayesian network structure learning: it can model any joint distribution given enough data by positing latent variables, but also discovers independencies between the observable variables.\n",
    "\n",
    "A range of exploratory analysis and predictive modeling tasks can be addressed via CrossCat, including detecting predictive relationships between variables, finding multiple overlapping clusterings, imputing missing values, and simultaneously selecting features and classifying rows. Research on CrossCat has shown that it is suitable for analysis of real-world tables of up to 10 million cells, including hospital cost and quality measures, voting records, handwritten digits, and state-level unemployment time series.\n",
    "\n",
    "## 3. VentureScript\n",
    "VentureScript is a higher-order probabilistic programming language that aims to be sufficiently expressive, extensible, and efficient for general-purpose use. Some distinctive features include:\n",
    "- Sufficient expressiveness to handle problems and data sources from multiple fields, such as machine learning, robotics and statistics.\n",
    "- An inference programming language that supports combinations of exact and approximate inference techniques, including Metropolis-Hastings, mean field, sequential Monte Carlo, Hamiltonian Monte Carlo and gradient descent.\n",
    "- A JavaScript-like front-end syntax and a read-write textual representation of the abstract syntax dervied from Lisp\n",
    "- A flexible foreign interface that makes it straightforward to add new primitives, including higher-order probabilistic procedures, exchangeable sequences, and “likelihood free” primitives, and to equip them with custom inference schemes.\n",
    "- An interactive console that provides tools for inspection, profiling and debugging.\n",
    "\n",
    "## 4. Gen.jl\n",
    "Gen.jl is a featherweight embedded probabilistic programming language and compositional inference programming library for [Julia](https://julialang.org/). \n",
    "\n",
    "## 5. Tutorial notebooks\n",
    "The notebooks in this folder contain several tutorials on using BayesDB to analyze real-world data, as well as a two-part Gen.jl tutorial on inferring goals of autonomous agents. For those with significant statistics and/or machine learning background, we also provide notebooks illustrating Gaussian process extrapolation and hyperparameter inference as probabilistic programming synthesis.\n",
    "\n",
    "Each notebook will be provided in two forms: a Jupyter notebook for you to work through and a pre-rendered HTML or pdf file of the results for you to refer to as you go. Please note that the cells in the Jupyter notebooks should be run in order.\n",
    "\n",
    "The notebooks use extensions loaded from `jupyter_probcomp`, including cell magics that enable running Bayesian Query Language (BQL) queries, Metamodeling Language (MML) queries, and VentureScript code inline within Jupyter code cells. The basic usage of the magics is described below.\n",
    "\n",
    "Single-line BQL query:  \n",
    "`%bql <query>`\n",
    "\n",
    "Multi-line BQL query:  \n",
    "`%%bql`  \n",
    "`<query line 1>`  \n",
    "`<query line 2>`  \n",
    "`...`\n",
    "\n",
    "MML magics (`%mml`, `%%mml`) and VentureScript magics (`%venturescript`, `%%venturescript`) operate similarly. SQL magics (`%sql`, `%%sql`) are also supported. \n",
    "\n",
    "### 5.0 Documentation\n",
    "You will encounter many common uses of `jupyter_probcomp` functions, BQL, MML, and VentureScript in the notebooks we have provided. For more information, please refer to the documentation:\n",
    "- [jupyter_probcomp](https://github.com/probcomp/iventure/blob/master/docs/dot_commands.md)\n",
    "- [BQL and MML](https://probcomp-1.csail.mit.edu/reference/bayeslite/bql.html) \n",
    "- [VentureScript](http://probcomp.csail.mit.edu/venture/edge/reference/)\n",
    "\n",
    "Gen.jl is still in early stages of development and thus does not have official documentation.\n",
    "\n",
    "\n",
    "The following sections suggest an order in which to work through the notebooks and provide a brief description of each notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Gapminder exploratory analysis tutorial\n",
    "The  [Gapminder exploratory analysis tutorial](./gapminder-exploratory.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/gapminder-exploratory.html)) contains a tutorial of exploratory data analysis in BayesDB. We cover the basics of loading data into data tables and creating populations and analysis schemas. We describe and visualize the outcomes of CrossCat, the default modeling building and discovery engine in BayesDB, as applied to the Gapminder dataset. We then compare probably dependencies detected by CrossCat to those discovered by linear methods such as Pearson correlation. The tutorial concludes by showing how to use BQL queries to search for database records which are probably predictive of another.\n",
    "\n",
    "### 5.2 Satellites predictive modeling tutorial\n",
    "The [satellites predictive modeling tutorial](./satellites-predictive.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/satellites-predictive.html)) contains a tutorial of predictive modeling and analysis in BayesDB. We cover how to simulate data from the learned CrossCat generative models, and compare the results of selecting and simulating the same data to show that CrossCat can recover both quantitative and qualitative features of the underlying data distribution. We also show how predictive probability in BayesDB can be used to detect anomalous values. \n",
    "\n",
    "### 5.3 Population assembly with BayesDB tutorial\n",
    "In the [population assembly tutorial](./population-assembly-tutorial.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/population-assembly-tutorial.html)), we demonstrate how to construct BayesDB analysis populations -- consisting of tabular, medium data with defined statistical types -- from a variety of data sources. We provide examples of population assembly from: (1) a neuroscience data source of fMRI imaging data plus a separate public database of word meanings, (2) the Gapminder international development data source, and (3) epidemiological data sources for tracking the spread of the flu including Twitter and CDC data.\n",
    "\n",
    "### 5.4 Gapminder missing data tutorial\n",
    "The [Gapminder missing data tutorial](./gapminder-missing-data.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/gapminder-missing-data.html)) shows how BayesDB can be used to find patterns of missing values in data and detect whether data are missing at random. This notebook also demonstrates how BayesDB  can be used to infer missing values and shows that the imputations generated by CrossCat are fairly well-calibrated. Both of theses analyses are conducted on a dataset from Gapminder.\n",
    "\n",
    "### 5.5 [optional] Goal inference with Gen.jl\n",
    "The [Gen.jl goal inference notebook part 1](./goal-inference-part1.ipynb) ([pdf](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/inferring-goals-1.pdf)) and [part 2](goal-inference-part2.ipynb) ([pdf](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/inferring-goals-2.pdf)) use the Gen.jl probabilistic meta-programming library to write probabilistic models of an autonomous agent and inference algorithms that infer the goals of the agent based on its observed behavior. The notebooks also introduce a methodology for visualization of probabilistic program execution traces and the behavior of inference algorithms, and illustrates the methodology using D3.js.\n",
    "\n",
    "### 5.6 [optional] Gaussian process extrapolation as probabilistic programming synthesis\n",
    "The [Gaussian process extrapolation notebook](./extrapolation-with-gp.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/extrapolation-with-gp.html)) demonstrates extrapolation with probabilistic programming synthesis given real world data. The notebook shows how extrapolation results improve with increasing time spent on inference. The notebook also compares the Gaussian process posterior predictive to the posterior predictive generated with Bayesian linear regression.\n",
    "\n",
    "### 5.7 [optional] Gaussian process hyperparameter inference as probabilistic programming synthesis\n",
    "The [Gaussian process hyperparameter inference notebook](./hyperparameter-inference-with-gp.ipynb) ([HTML](https://probcomp-1.csail.mit.edu/6d03d3f3cf4c0e22755f471f5ebfe5f6/20170627-oreilly/hyperparameter-inference-with-gp.html)) demonstrates hyperparameter inference in the probabilistic programming synthesis framework. We compare Metropolis-Hastings sampling and gradient ascent as two synthesis strategies for inference over GP hyperparameters; for this comparison we inspect how inference strategies explore the posterior landscape and how the Gaussian process posterior predictive differs for different inference strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. This machine\n",
    "\n",
    "If needed, you can administer the computer this is running on from the main Jupyter page, by selecting \"New -> Terminal\".  The operating system is Ubuntu 16.04, and that terminal will be logged in as the `ubuntu` user, with passwordless sudo privileges.\n",
    "\n",
    "In particular, you can\n",
    "\n",
    "- Change the Jupyter notebook password by opening the terminal and typing `jupyter notebook password`.\n",
    "\n",
    "- Give yourself SSH access to this host by adding your SSH public key to `~/.ssh/authorized_keys`, whereupon you will be able to log in to `ssh.<username>.stack.probcomp.net` with the corresponding private key.  The host keys are stored in `/etc/ssh/` as usual.\n",
    "\n",
    "A note about the Python setup.  Python and our software are installed into a virtualenv that lives at `~/.venv`.  The Jupyter notebook server is started in the context of this virtualenv, and any terminals opened through Jupyter inherit that context.  However, any independent logins to `ssh.<username>.stack.probcomp.net` start outside the virtualenv, and one would need to explicitly activate it in order to manipulate the Python installation seen by the Jupyter server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
